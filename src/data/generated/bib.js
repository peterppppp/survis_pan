define({ entries : {
    "BalazMarek2023TIoM": {
        "abstract": "Monte-Carlo tree search (MCTS) is a widely used heuristic search algorithm. In model-based reinforcement learning, MCTS is often utilized to improve action selection process. However, model-based reinforcement learning methods need to process large number of observations during the training. If MCTS is involved, it is necessary to run one instance of MCTS for each observation in every iteration of training. Therefore, there is a need for efficient method to process multiple instances of MCTS. We propose a MCTS implementation that can process batch of observations in fully parallel fashion on a single GPU using tensor operations. We demonstrate efficiency of the proposed approach on a MuZero reinforcement learning algorithm. Empirical results have shown that our method outperforms other approaches and scale well with increasing number of observations and simulations.",
        "address": "BASEL",
        "author": "Balaz, Marek and Tarabek, Peter",
        "copyright": "Copyright 2023 Elsevier B.V., All rights reserved.",
        "doi": "10.3390/app13031406",
        "issn": "2076-3417",
        "journal": "Applied sciences",
        "keywords": "Algorithms ; Artificial intelligence ; Chemistry ; Chemistry Multidisciplinary ; Decision making ; Engineering ; Engineering Multidisciplinary ; Free agency ; Learning ; Materials Science ; Materials Science Multidisciplinary ; Methods ; model-based reinforcement learning ; Monte-Carlo tree search ; MuZero ; parallel computations ; Physical Sciences ; Physics ; Physics Applied ; Reinforcement ; reinforcement learning ; Science & Technology ; Search algorithms ; Simulation ; Technology ; tensor GPU implementation",
        "language": "eng",
        "number": "3",
        "pages": "1406",
        "publisher": "Mdpi",
        "series": "Controlled User Study",
        "title": "Tensor Implementation of Monte-Carlo Tree Search for Model-Based Reinforcement Learning",
        "type": "article",
        "url": "https://mdpi-res.com/applsci/applsci-13-01406/article_deploy/applsci-13-01406-v2.pdf?version",
        "volume": "13",
        "year": "2023"
    },
    "KemmerlingMarco2024Bgas": {
        "abstract": "The advent of AlphaGo and its successors marked the beginning of a new paradigm in playing games using artificial intelligence. This was achieved by combining Monte Carlo tree search, a planning procedure, and deep learning. While the impact on the domain of games has been undeniable, it is less clear how useful similar approaches are in applications beyond games and how they need to be adapted from the original methodology. We perform a systematic literature review of peer-reviewed articles detailing the application of neural Monte Carlo tree search methods in domains other than games. Our goal is to systematically assess how such methods are structured in practice and if their success can be extended to other domains. We find applications in a variety of domains, many distinct ways of guiding the tree search using learned policy and value functions, and various training methods. Our review maps the current landscape of algorithms in the family of neural monte carlo tree search as they are applied to practical problems, which is a first step towards a more principled way of designing such algorithms for specific problems and their requirements.",
        "address": "New York",
        "author": "Kemmerling, Marco and L\u00fctticke, Daniel and Schmitt, Robert H.",
        "copyright": "The Author(s) 2023",
        "doi": "10.1007/s10489-023-05240-w",
        "issn": "0924-669X",
        "journal": "Applied intelligence (Dordrecht, Netherlands)",
        "keywords": "Algorithms ; Artificial Intelligence ; Computer Science ; Decision-time planning ; Games ; Literature reviews ; Machine learning ; Machines ; Manufacturing ; MCTS ; Mechanical Engineering ; Model-based reinforcement learning ; Monte Carlo simulation ; Monte carlo tree search ; Neural monte carlo tree search ; Processes ; Reinforcement learning ; Search algorithms ; Search methods",
        "language": "eng",
        "number": "1",
        "pages": "1020--1046",
        "publisher": "Springer US",
        "series": "Literature Review",
        "title": "Beyond games: a systematic review of neural Monte Carlo tree search applications",
        "type": "article",
        "url": "https://link.springer.com/content/pdf/10.1007/s10489-023-05240-w.pdf",
        "volume": "54",
        "year": "2024"
    },
    "LiShuqin2020Roic": {
        "abstract": "Situation assessment and search are two key problems in computer game research. In general, as the game progresses, the difficulty of evaluating the situation of the game is significantly reduced, and the accuracy of the evaluation is significantly increased. Based on the famous chess game, this article proposes and implements a new scheme that combines the Monte Carlo tree search algorithm, the Alpha-Beta algorithm and the model based on the deep convolution neural network (CNN) to solve the computer game problem. This article first proposes a deep convolutional neural network model based on dots and boxes, including deep value network and deep strategy network, focusing on situation assessment and strategy recommendation, respectively. Then, using the Monte Carlo Tree Search (MCTS) algorithm as a framework, deep value network integrated MCTS algorithm and deep strategy network integrated MCTS algorithm are proposed. In both integrated models, Alpha-Beta complete search is used to truncate the Monte Carlo simulation process and improve simulation efficiency. Through competition with human players, the results show that the two integrated algorithm game systems have reached much higher intelligence level than ordinary humans in solving the problem of dots and boxes.",
        "address": "HERTFORD",
        "author": "Li, Shuqin and Zhang, Yipeng and Ding, Meng and Dai, Pengcheng",
        "copyright": "2021 The Institution of Engineering and Technology",
        "doi": "10.1049/joe.2019.1185",
        "issn": "2051-3305",
        "journal": "Journal of engineering (Stevenage, England)",
        "keywords": "Alpha\u2010Beta algorithm ; Alpha\u2010Beta complete search ; artificial intelligence ; C++ language ; computer game problem ; computer game research ; computer games ; deep convolution neural network ; deep convolutional neural network model ; deep strategy network integrated MCTS algorithm ; deep value network ; dots ; Engineering ; Engineering Multidisciplinary ; famous chess game ; game progresses ; game theory ; integrated algorithm game systems ; integrated models ; Monte Carlo methods ; Monte Carlo simulation process ; Monte Carlo tree search algorithm ; neural nets ; research on integrated computer game algorithm ; Science & Technology ; situation assessment ; strategy recommendation ; Technology ; The 3rd Asian Conference on Artificial Intelligence Technology (ACAIT 2019) ; tree searching",
        "language": "eng",
        "number": "13",
        "pages": "601--606",
        "publisher": "The Institution of Engineering and Technology",
        "series": "Controlled User Study",
        "title": "Research on integrated computer game algorithm for dots and boxes",
        "type": "article",
        "url": "https://ietresearch.onlinelibrary.wiley.com/doi/epdf/10.1049/joe.2019.1185",
        "volume": "2020",
        "year": "2020"
    },
    "LiuPengsen2023Etfb": {
        "abstract": "In most chess games without additional rule restrictions, the side that makes the first move (i.e., the first-move side) has an absolute advantage, which affects the game\u2019s balance to a certain extent. Artificial intelligence (AI) training in some chess games can be bottlenecked by the imbalance of opening moves, making it challenging to improve chess strength. The first-move balance problem can be explored to achieve a balanced win rate in chess games. This study uses Go-Moku as an example to explore the first-move balance point problem for different sizes of Go-Moku boards. We design a self-playing Go-Moku intelligence algorithm using deep reinforcement learning and Monte Carlo tree search (MCTS), which can considerably save arithmetic power without affecting the strength of the AI. To address the characteristics of Go-Moku and its complexity, we propose an algorithm using dynamic MCTS simulation counts, which only employs a reasonable amount of hyperparameters to achieve better performance with the cost of a relatively small number of simulations. By symmetrically expanding the data and optimizing the exploration and selection allocation, the training efficiency of the Go-Moku AI is improved through Multiple Process Interface (MPI) multi-processes. Building the test model of first-move balance points for a universal Go-Moku board, we obtain a set of first-move balance points for different board sizes. The first-move balance point of Go-Moku that makes the game even is found by simulating the game win rate for all first-move drop points. The experimental results demonstrate that the proposed algorithm can achieve world-leading chess strength in Gomocup by engine play tests and can find the first-move balance point of Go-Moku on boards of various sizes. The results of this study will help optimize the rule setting of Go-Moku and improve the training efficiency of AI in the field of Go-Moku, which can be extended to the exploration of balance in other chess games.",
        "address": "AMSTERDAM",
        "author": "Liu, Pengsen and Zhou, Jizhe and Lv, Jiancheng",
        "copyright": "2022 Elsevier B.V.",
        "doi": "10.1016/j.knosys.2022.110207",
        "issn": "0950-7051",
        "journal": "Knowledge-based systems",
        "keywords": "Computer Science ; Computer Science Artificial Intelligence ; First-move balance problem ; Go-Moku ; Monte Carlo tree search ; Reinforcement learning ; Science & Technology ; Technology",
        "language": "eng",
        "pages": "110207",
        "publisher": "Elsevier B.V",
        "series": "Case Study",
        "title": "Exploring the first-move balance point of Go-Moku based on reinforcement learning and Monte Carlo tree search",
        "type": "article",
        "url": "https://www.sciencedirect.com/science/article/abs/pii/S095070512201303X?via%3Dihub",
        "volume": "261",
        "year": "2023"
    },
    "LuoRuifeng2022AMCT": {
        "abstract": "Truss layout optimization under complex constraints has been a hot and challenging problem for decades that aims to find the optimal node locations, connection topology between nodes, and cross-sectional areas of connecting bars. Monte Carlo Tree Search (MCTS) is a reinforcement learning search technique that is competent to solve decision-making problems. Inspired by the success of AlphaGo using MCTS, the truss layout problem is formulated as a Markov Decision Process (MDP) model, and a 2-stage MCTS-based algorithm, AlphaTruss, is proposed for generating optimal truss layout considering topology, geometry, and bar size. In this MDP model, three sequential action sets of adding nodes, adding bars, and selecting sectional areas greatly expand the solution space and the reward function gives feedback to actions according to both geometric stability and structural simulation. To find the optimal sequential actions, AlphaTruss solves the MDP model and gives the best decision in each design step by searching and learning through MCTS. Compared with existing results from the literature, AlphaTruss exhibits better performance in finding the truss layout with the minimum weight under stress, displacement, and buckling constraints, which verifies the validity and efficiency of the established algorithm.",
        "address": "BASEL",
        "author": "Luo, Ruifeng and Wang, Yifan and Xiao, Weifang and Zhao, Xianzhong",
        "copyright": "Copyright 2022 Elsevier B.V., All rights reserved.",
        "doi": "10.3390/buildings12050641",
        "issn": "2075-5309",
        "journal": "Buildings (Basel)",
        "keywords": "Algorithms ; Artificial intelligence ; Buckling ; computational intelligence ; Construction & Building Technology ; Decision making ; Design optimization ; Engineering ; Engineering Civil ; Layouts ; Learning ; Markov processes ; Minimum weight ; Monte Carlo method ; Monte Carlo Tree Search ; Nodes ; Optimization ; Reinforcement ; reinforcement learning ; Science & Technology ; Searching ; simulation-based optimization ; Solution space ; Structural stability ; Technology ; Topology ; truss layout design ; Trusses",
        "language": "eng",
        "number": "5",
        "pages": "641",
        "publisher": "Mdpi",
        "series": "Case Study",
        "title": "AlphaTruss: Monte Carlo Tree Search for Optimal Truss Layout Design",
        "type": "article",
        "url": "https://mdpi-res.com/buildings/buildings-12-00641/article_deploy/buildings-12-00641-v2.pdf?version",
        "volume": "12",
        "year": "2022"
    },
    "MoZhaobin2023RDSi": {
        "abstract": "How to sample training/validation data is an important question for machine learning models, especially when the dataset is heterogeneous and skewed. In this paper, we propose a data sampling method that robustly selects training/validation data. We formulate the training/validation data sampling process as a two-player game: a trainer aims to sample training data so as to minimize the test error, while a validator adversarially samples validation data that can increase the test error. Robust sampling is achieved at the game equilibrium. To accelerate the searching process, we adopt reinforcement learning aided Monte Carlo trees search (MCTS). We apply our method to a car-following modeling problem, a complicated scenario with heterogeneous and random human driving behavior. Real-world data, the Next Generation SIMulation (NGSIM), is used to validate this method, and experiment results demonstrate the sampling robustness and thereby the model out-of-sample performance.",
        "address": "BASEL",
        "author": "Mo, Zhaobin and Di, Xuan and Shi, Rongye",
        "copyright": "Copyright 2023 Elsevier B.V., All rights reserved.",
        "doi": "10.3390/g14010013",
        "issn": "2073-4336",
        "journal": "Games",
        "keywords": "Business & Economics ; car-following modeling ; Economics ; Equipment and supplies ; Machine learning ; Mathematical Methods In Social Sciences ; Mathematics ; Mathematics Interdisciplinary Applications ; Monte Carlo tree search ; Physical Sciences ; reinforcement learning ; Science & Technology ; Social Sciences ; Social Sciences Mathematical Methods ; Teaching ; two-player game",
        "language": "eng",
        "number": "1",
        "pages": "13",
        "publisher": "Mdpi",
        "series": "Controlled User Study",
        "title": "Robust Data Sampling in Machine Learning: A Game-Theoretic Framework for Training and Validation Data Selection",
        "type": "article",
        "url": "https://mdpi-res.com/games/games-14-00013/article_deploy/games-14-00013.pdf?version",
        "volume": "14",
        "year": "2023"
    },
    "PanChao-Fan2023Bioi": {
        "abstract": "Modeling and predicting player behavior is of the utmost importance in game development and matchmaking. A variety of methods have been proposed to build artificial intelligence (AI), human-like players. However, these human-like players have a limited ability to imitate the behavior of individual players. In this paper, we propose a player behavior imitation method using imitation learning under the framework of meta-learning. A generic behavior model of game players was learned from historical records using adversarial imitation learning. Then, we personalized the policy by imitating the behavior of each individual player. Convolutional neural networks were used to construct the feature extractor of game board states. The experiments were conducted using the Reversi game, and 18,000 game records of different players were used to train the generic behavior model. The behavior of each new player was learned using only hundreds of records. The results demonstrate that our method can be utilized to imitate individual behavior in terms of action similarity well.",
        "address": "New York",
        "author": "Pan, Chao-Fan and Min, Xue-Yang and Zhang, Heng-Ru and Song, Guojie and Min, Fan",
        "copyright": "The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2022. Springer Nature or its licensor holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.",
        "doi": "10.1007/s10489-022-04050-w",
        "issn": "0924-669X",
        "journal": "Applied intelligence (Dordrecht, Netherlands)",
        "keywords": "Artificial Intelligence ; Artificial neural networks ; Behavior ; Behavior imitation ; Computer Science ; Computer Science Artificial Intelligence ; Games ; Gaming ; Imitation learning ; Learning ; Machines ; Manufacturing ; Mechanical Engineering ; Meta-learning ; Performance evaluation ; Players ; Processes ; Science & Technology ; Technology",
        "language": "eng",
        "number": "10",
        "pages": "11571--11585",
        "publisher": "Springer US",
        "series": "Case Study",
        "title": "Behavior imitation of individual board game players",
        "type": "article",
        "url": "https://link-springer-com.nottingham.idm.oclc.org/content/pdf/10.1007/s10489-022-04050-w.pdf",
        "volume": "53",
        "year": "2023"
    },
    "RossatoLanaBertoldo2023ETGD": {
        "abstract": "Creating and evaluating games manually is an arduous and laborious task. Procedural content generation can aid by creating game artifacts, but usually not an entire game. Evolutionary game design, which combines evolutionary algorithms with automated playtesting, has been used to create novel board games with simple equipment; however, the original approach does not include complex tabletop games with dice, cards, and maps. This work proposes an extension of the approach for tabletop games, evaluating the process by generating variants of Risk, a military strategy game where players must conquer map territories to win. We achieved this using a genetic algorithm to evolve the chosen parameters, as well as a rules-based agent to test the games and a variety of quality criteria to evaluate the new variations generated. Our results show the creation of new variations of the original game with smaller maps, resulting in shorter matches. Also, the variants produce more balanced matches, maintaining the usual drama. We also identified limitations in the process, where, in many cases, where the objective function was correctly pursued, but the generated games were nearly trivial. This work paves the way towards promising research regarding the use of evolutionary game design beyond classic board games.",
        "address": "NEW YORK",
        "author": "Rossato, Lana Bertoldo and Bombardelli, Leonardo Boaventura and Tavares, Anderson Rocha",
        "booktitle": "ACM International Conference Proceeding Series",
        "copyright": "Copyright 2024 Elsevier B.V., All rights reserved.",
        "doi": "10.1145/3631085.3631236",
        "isbn": "9798400716270",
        "keywords": "Computer Science ; Computer Science Interdisciplinary Applications ; Computer Science Software Engineering ; Computer Science Theory & Methods ; Evolutionary Game Design ; Genetic Algorithm ; Risk ; Science & Technology ; Technology",
        "language": "eng",
        "organization": "ACM",
        "pages": "161--170",
        "publisher": "Assoc Computing Machinery",
        "series": "Case Study",
        "title": "Evolutionary Tabletop Game Design: A Case Study in the Risk Game",
        "type": "inproceedings",
        "url": "https://dl-acm-org.nottingham.idm.oclc.org/doi/pdf/10.1145/3631085.3631236",
        "year": "2023"
    },
    "RossiLeonardo2022MCTS": {
        "abstract": "Monte Carlo Tree Search (MCTS) is a search technique that in the last decade emerged as a major breakthrough for Artificial Intelligence applications regarding board- and video-games. In 2016, AlphaGo, an MCTS-based software agent, outperformed the human world champion of the board game Go. This game was for long considered almost infeasible for machines, due to its immense search space and the need for a long-term strategy. Since this historical success, MCTS is considered as an effective new approach for many other scientific and technical problems. Interestingly, civil structural engineering, as a discipline, offers many tasks whose solution may benefit from intelligent search and in particular from adopting MCTS as a search tool. In this work, we show how MCTS can be adapted to search for suitable solutions of a structural engineering design problem. The problem consists of choosing the load-bearing elements in a reference reinforced concrete structure, so to achieve a set of specific dynamic characteristics. In the paper, we report the results obtained by applying both a plain and a hybrid version of single-agent MCTS. The hybrid approach consists of an integration of both MCTS and classic Genetic Algorithm (GA), the latter also serving as a term of comparison for the results. The study\u2019s outcomes may open new perspectives for the adoption of MCTS as a design tool for civil engineers.",
        "address": "London",
        "author": "Rossi, Leonardo and Winands, Mark H. M. and Butenweg, Christoph",
        "copyright": "The Author(s) 2021",
        "doi": "10.1007/s00366-021-01338-2",
        "issn": "0177-0667",
        "journal": "Engineering with computers",
        "keywords": "Artificial intelligence ; CAE) and Design ; Calculus of Variations and Optimal Control; Optimization ; Civil engineering ; Civil engineers ; Classical Mechanics ; Computer & video games ; Computer Science ; Computer Science Interdisciplinary Applications ; Computer-Aided Engineering (CAD ; Concrete structures ; Control ; Design engineering ; Dynamic characteristics ; Engineering ; Engineering Mechanical ; Genetic algorithm ; Genetic algorithms ; Load bearing elements ; Math. Applications in Chemistry ; Mathematical and Computational Engineering ; Monte Carlo method ; Monte Carlo Tree Search ; Original Article ; Reinforced concrete ; Reinforced concrete buildings ; Science & Technology ; Searching ; Software agents ; Structural design ; Structural engineering ; Systems Theory ; Technology",
        "language": "eng",
        "number": "4",
        "pages": "3219--3236",
        "publisher": "Springer London",
        "series": "Controlled User Study",
        "title": "Monte Carlo Tree Search as an intelligent search tool in structural design problems",
        "type": "article",
        "url": "https://link.springer.com/content/pdf/10.1007/s00366-021-01338-2.pdf",
        "volume": "38",
        "year": "2022"
    },
    "SironiChiaraF.2021AotI": {
        "abstract": "Monte-Carlo Tree Search (MCTS) has been applied successfully in many domains, including games. However, its performance is not uniform on all domains, and it also depends on how parameters that control the search are set. Parameter values that are optimal for a task might be sub-optimal for another. In a domain that tackles many games with different characteristics, like general game playing (GGP), selecting appropriate parameter settings is not a trivial task. Games are unknown to the player, thus, finding optimal parameters for a given game in advance is not feasible. Previous work has looked into tuning parameter values online, while the game is being played, showing some promising results. This tuning approach looks for optimal parameter values, balancing exploitation of values that performed well so far in the search and exploration of less sampled values. Continuously changing parameter values while performing the search, combined also with exploration of multiple values, introduces some randomization in the process. In addition, previous research indicates that adding randomization to certain components of MCTS might increase the diversification of the search and improve the performance. Therefore, this article investigates the effect of randomly selecting values for MCTS search-control parameters online among predefined sets of reasonable values. For the GGP domain, this article evaluates four different online parameter randomization strategies by comparing them with other methods to set parameter values: online parameter tuning, offline parameter tuning and sub-optimal parameter choices. Results on a set of 14 heterogeneous abstract games show that randomizing parameter values before each simulation has a positive effect on the search in some of the tested games, with respect to using fixed offline-tuned parameters. Moreover, results show a clear distinction between games for which online parameter tuning works best and games for which online randomization works best. In addition, the overall performance of online parameter randomization is closer to the one of online parameter turning than the one of sub-optimal parameter values, showing that online randomization is a reasonable parameter selection strategy. When analyzing the structure of the search trees generated by agents that use the different parameters selection strategies, it is clear that randomization causes MCTS to become more explorative, which is helpful for alignment games that present many winning paths in their trees. Online parameter tuning, instead, seems more suitable for games that present narrow winning paths and many losing paths.",
        "address": "MARINA DEL REY",
        "author": "Sironi, Chiara F. and Winands, Mark H.M.",
        "copyright": "Copyright 2021 Elsevier B.V., All rights reserved.",
        "doi": "10.1613/jair.1.12065",
        "issn": "1076-9757",
        "journal": "The Journal of artificial intelligence research",
        "keywords": "Computer Science ; Computer Science Artificial Intelligence ; Domains ; Game theory ; Games ; Impact analysis ; Monte Carlo method ; Parameters ; Performance enhancement ; Randomization ; Science & Technology ; Searching ; Technology ; Trees ; Tuning",
        "language": "eng",
        "pages": "715--757",
        "publisher": "Ai Access Foundation",
        "series": "Case Study",
        "title": "Analysis of the Impact of Randomization of Search-Control Parameters in Monte-Carlo Tree Search",
        "type": "article",
        "url": "https://jair.org/index.php/jair/article/view/12065/26735",
        "volume": "72",
        "year": "2021"
    }
}});